library(arules)
install.packages("arules")
a <- c(1,1,0,0,1,1,0,1)
b <- c(0,1,0,1,1,0,0,0)
c <- c(0,1,1,0,1,1,1,0)
goal <- c(1,0,1,0,1,1,1,1)
myDF <- cbind(a, b, c, goal)
library(arules)
apriori(myDF, parameter = NULL, appearance = NULL, control = NULL)
apriori(myDF, parameter = list(target = "rules"), appearance = list(rhs = "goal"), control = NULL)
regras <- apriori(myDF, parameter = list(target = "rules"), appearance = list(rhs = "goal"), control = NULL)
View(regras)
regras
inspect(regras)
entropia <- function(a,b){
total <- a + b
return (a/total) * log2(a/total) - (b/total) * log2(b/total)
}
entropia(22,13)
entropia(19,2)
entropia(3,11)
entropia(19,2) + entropia(3,11) - entropia(22,13)
entropia <- function(a,b){
total <- a + b
return -((a/total) * log2(a/total) + (b/total) * log2(b/total))
}
entropia(22,13)
entropia <- function(a,b){
total <- a + b
return (-(a/total) * log2(a/total) - (b/total) * log2(b/total))
}
entropia(22,13)
entropia(19,2)
entropia(3,11)
entropia(19,2) + entropia(3,11) - entropia(22,13)
install.packages("rpart")
install.packages("rpart.plot")
data(mtcars)
force(mtcars)
data(mtcars)
mtcars$kpl <- mtcars$mpg * 0.425
mtcars$peso <- mtcars$wt * 0.453
cambio <- factor(mtcars$am, levels = c(0, 1), labels=c("Automático", "Manual"))
modelo <- lm(peso~kpl, data=mtcars)
View(modelo)
install.packages("ggplot2")
library(ggplot2)
qplot(peso, kpl, data = modelo, color = cambio, shape = cambio, geom = c("point", "smooth"), xlab = "Peso (em toneladas)", ylab = "Km/l", main = "Modelo de regressão")
install.packages("UsingR")
library(UsingR)
data(galton)
data(Galton)
library(UsingR)
data(Galton)
force(Galton)
dadosFr <- as.data.frame(table(x, y))
dt <- data.frame(Galton)
dt <- lapply(dt, function(x), x/39.37)
dt <- data.frame(dt)
View(dt)
x <- as.vector(dt$parent - mean(dt$parent))
y <- as.vector(dt$child - mean(dt$child))
dadosFr <- as.data.frame(table(x, y))
View(dadosFr)
library(ggplot2)
qplot(dadosFr)
plot(dadosFr)
View(dadosFr)
names(dadosFr)[1] <- "parent"
names(dadosFr)[2] <- "child"
View(dadosFr)
qplot(dadosFr$parent, dadosFr$child, data = dadosFr, color = dadosFr$Freq, shape = cambio, geom = c("point", "smooth"), xlab = "Peso (em toneladas)", ylab = "Km/l", main = "Modelo de regressão")
plot(dadosFr$Freq)
plot(as.vector(dadosFr$parent), as.vector(dadosFr$child), cex = dadosFr$Freq*0.1)
#!/usr/bin/env Rscript
library(arules)
# LÃª os arquivos
topics            <- data.frame(read.csv("dataset/topics_final.csv"           , header = TRUE, sep = ";"))
papers_subt_noise <- data.frame(read.csv("dataset/papers_subt_noise_final.csv", header = TRUE, sep = ","))
papers_data_noise <- data.frame(read.csv("dataset/papers_data_noise_final.csv", header = TRUE, sep = ","))
# Faz o merge entre eles
papers_data_subt_noise  <- merge(papers_data_noise,papers_subt_noise, by = 'paper')
dados <- merge(papers_data_subt_noise,topics, by.x ='subtopics', by.y ='subtopic')
dados$status = as.numeric(dados$status)
for (i in 1:6){
dados[,i] = as.factor(dados[,i])
}
# Transforma em transaÃ§Ãµes
dados2 <- as(dados, "transactions")
# Gera regras utilizando o algoritmo apriori
rules <- sort(apriori(data = dados2, parameter = list(support = 0.01, confidence = 0.6)), by = "support")
capture.output(inspect(rules),file = "resultados/rules_todas.txt")
# Escreve arquivos
write.table(dados,"resultados/dados_agrupados.csv", sep = ",", row.names = FALSE)
# Subareas que historicamente tem maior possibilidade de aceite
subarea <- sort(subset(rules, (size(lhs) == 1) & (lhs  %pin% "subtopics=") & (rhs %in% "status=1")), by = "support")
# Escreve arquivo com as regras
capture.output(inspect(subarea),file = "resultados/regras_subareas.txt")
# Converte coluna status para nÃºmero
dados$status = as.numeric(dados$status)
# Aplica o kmeans
# NÃºmero de conferencias por ano nÃ£o Ã© constante. Entre 2010 e 2012 e em 2016, foram duas conferencias por ano. JÃ¡ em 2013, 2014 e 2017 apenas uma. E no ano de 2015 foram 3 conferencias.
# year X status
teste <- kmeans(dados[,4,5],8)
capture.output(teste$size,teste$centers,teste$withinss,table(teste$cluster, dados$conf),file = "resultados/conf.txt")
# subtopicos 63,64,66,67,68 sÃ£o novos e subtopico 65 nÃ£o tem paper
#
# 2	 Service Management	63	 IoT Services
# 2	 Service Management	64	 Security Services
# 3	 Business Management	66	 Economic Aspects
# 6	 Technologies	67	 Software-Defined Networking
# 6	 Technologies	68	 Network Function Virtualization
# 3	 Business Management	65	 Regulatory Perspective
capture.output(teste$size,teste$centers,teste$withinss,table(teste$cluster, dados$subtopics),file="resultados/sub.txt")
# subtopicos 6, 20, 38 tem mais rejeiÃ§Ãµes que aceites
# status X topic
teste <- kmeans(dados[,5,6],2)
capture.output(teste$size,teste$centers,teste$withinss,table(teste$cluster, dados$subtopics),file="resultados/mais.txt")
library(arules)
# LÃª os arquivos
topics            <- data.frame(read.csv("dataset/topics_final.csv"           , header = TRUE, sep = ";"))
setwd("C:\\Users\\kikog\\Documents\\UFSM\\6º Semestre\\Mineração de Dados\\TFINAL\\mineracao-trab2 (2)\\mineracao-trab2")
library(arules)
# LÃª os arquivos
topics            <- data.frame(read.csv("dataset/topics_final.csv"           , header = TRUE, sep = ";"))
papers_subt_noise <- data.frame(read.csv("dataset/papers_subt_noise_final.csv", header = TRUE, sep = ","))
papers_data_noise <- data.frame(read.csv("dataset/papers_data_noise_final.csv", header = TRUE, sep = ","))
# Faz o merge entre eles
papers_data_subt_noise  <- merge(papers_data_noise,papers_subt_noise, by = 'paper')
dados <- merge(papers_data_subt_noise,topics, by.x ='subtopics', by.y ='subtopic')
dados$status = as.numeric(dados$status)
for (i in 1:6){
dados[,i] = as.factor(dados[,i])
}
# Transforma em transaÃ§Ãµes
dados2 <- as(dados, "transactions")
# Gera regras utilizando o algoritmo apriori
rules <- sort(apriori(data = dados2, parameter = list(support = 0.01, confidence = 0.6)), by = "support")
capture.output(inspect(rules),file = "resultados/rules_todas.txt")
# Escreve arquivos
write.table(dados,"resultados/dados_agrupados.csv", sep = ",", row.names = FALSE)
# Subareas que historicamente tem maior possibilidade de aceite
subarea <- sort(subset(rules, (size(lhs) == 1) & (lhs  %pin% "subtopics=") & (rhs %in% "status=1")), by = "support")
# Escreve arquivo com as regras
capture.output(inspect(subarea),file = "resultados/regras_subareas.txt")
# Converte coluna status para nÃºmero
dados$status = as.numeric(dados$status)
# Aplica o kmeans
# NÃºmero de conferencias por ano nÃ£o Ã© constante. Entre 2010 e 2012 e em 2016, foram duas conferencias por ano. JÃ¡ em 2013, 2014 e 2017 apenas uma. E no ano de 2015 foram 3 conferencias.
# year X status
teste <- kmeans(dados[,4,5],8)
capture.output(teste$size,teste$centers,teste$withinss,table(teste$cluster, dados$conf),file = "resultados/conf.txt")
# subtopicos 63,64,66,67,68 sÃ£o novos e subtopico 65 nÃ£o tem paper
#
# 2	 Service Management	63	 IoT Services
# 2	 Service Management	64	 Security Services
# 3	 Business Management	66	 Economic Aspects
# 6	 Technologies	67	 Software-Defined Networking
# 6	 Technologies	68	 Network Function Virtualization
# 3	 Business Management	65	 Regulatory Perspective
capture.output(teste$size,teste$centers,teste$withinss,table(teste$cluster, dados$subtopics),file="resultados/sub.txt")
# subtopicos 6, 20, 38 tem mais rejeiÃ§Ãµes que aceites
# status X topic
teste <- kmeans(dados[,5,6],2)
capture.output(teste$size,teste$centers,teste$withinss,table(teste$cluster, dados$subtopics),file="resultados/mais.txt")
View(papers_data_subt_noise)
View(papers_subt_noise)
View(papers_data_noise)
View(papers_data_subt_noise)
View(dt)
View(Galton)
View(topics)
View(teste)
View(subarea)
View(rules)
View(papers_subt_noise)
View(papers_data_subt_noise)
